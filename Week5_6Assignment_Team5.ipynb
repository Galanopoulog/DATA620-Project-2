{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import pandas as pd\n",
    "import sys\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.api import TokenizerI\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "toktok = ToktokTokenizer()\n",
    "\n",
    "\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724227031</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>Two places I'd invest all my money if I could:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724227032</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>Awesome! Google driverless cars will help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724227033</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>If Google maps can't keep up with road constru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724227034</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>Autonomous cars seem way overhyped given the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724227035</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Just saw Google self-driving car on I-34. It w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>724227036</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Will driverless cars eventually replace taxi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>724227037</td>\n",
       "      <td>not_relevant</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>Chicago metro expected to be fully autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>724227038</td>\n",
       "      <td>not_relevant</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>I love the infotainment system in my new car. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>724227039</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>Autonomous vehicles could reduce traffic fatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>724227040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>Driverless cars are not worth the risk.  Don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>724227041</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>Driverless cars are now legal in Florida, Cali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id     sentiment  sentiment:confidence  \\\n",
       "0   724227031             5                0.7579   \n",
       "1   724227032             5                0.8775   \n",
       "2   724227033             2                0.6805   \n",
       "3   724227034             2                0.8820   \n",
       "4   724227035             3                1.0000   \n",
       "5   724227036             3                1.0000   \n",
       "6   724227037  not_relevant                0.5367   \n",
       "7   724227038  not_relevant                0.6548   \n",
       "8   724227039             5                0.7187   \n",
       "9   724227040             1                0.6412   \n",
       "10  724227041             3                0.9184   \n",
       "\n",
       "                                                 text  \n",
       "0   Two places I'd invest all my money if I could:...  \n",
       "1   Awesome! Google driverless cars will help the ...  \n",
       "2   If Google maps can't keep up with road constru...  \n",
       "3   Autonomous cars seem way overhyped given the t...  \n",
       "4   Just saw Google self-driving car on I-34. It w...  \n",
       "5   Will driverless cars eventually replace taxi d...  \n",
       "6   Chicago metro expected to be fully autonomous ...  \n",
       "7   I love the infotainment system in my new car. ...  \n",
       "8   Autonomous vehicles could reduce traffic fatal...  \n",
       "9   Driverless cars are not worth the risk.  Don't...  \n",
       "10  Driverless cars are now legal in Florida, Cali...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.io.parsers.read_csv(\"https://raw.githubusercontent.com/Galanopoulog/DATA620-Assignment-6/master/Self-Driving-Cars.csv\")\n",
    "data = data.drop(data.columns[[1,2,3,4,7,8,9]], axis=1)\n",
    "data.text.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True) #remove ascii characters from text\n",
    "data.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7156\n"
     ]
    }
   ],
   "source": [
    "len(data)\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant: 6943\n",
      "Not_Relevant:  213\n",
      "Neutral:  4245\n"
     ]
    }
   ],
   "source": [
    "# Count relevant and irrelevant\n",
    "rel_count = len(data[data.sentiment!=\"not_relevant\"])\n",
    "irrel_count = len(data[data.sentiment==\"not_relevant\"])\n",
    "neut_count = len(data[data.sentiment==\"3\"])\n",
    "\n",
    "print \"Relevant:\",rel_count\n",
    "print \"Not_Relevant: \", irrel_count\n",
    "print \"Neutral: \", neut_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 5009\n",
      "Evaluation set: 1073\n",
      "Testing set: 1074\n",
      "Total: 7156\n"
     ]
    }
   ],
   "source": [
    "# What sizes should our sets be?\n",
    "train_set = int(0.7 * len(data))\n",
    "dev_set = int(.15 * len(data))\n",
    "final_set = len(data) - train_set - dev_set\n",
    "Total = train_set + dev_set + final_set\n",
    "\n",
    "print \"Training set: %d\" %train_set\n",
    "print \"Evaluation set: %d\" %dev_set\n",
    "print \"Testing set: %d\" %final_set\n",
    "print \"Total: %d\" %Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4860\n",
      "Evaluation set: 1041\n",
      "Testing set: 1042\n",
      "Total: 6943\n",
      "----------------------\n",
      "Training set: 149\n",
      "Evaluation set: 31\n",
      "Testing set: 33\n",
      "Total: 213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's split our data into relevant and non-relevant parts.\n",
    "relevant = data[data.sentiment!=\"not_relevant\"]\n",
    "nonrelevant = data[data.sentiment==\"not_relevant\"]\n",
    "\n",
    "# Let's take 70%, 15% and the 15% of each\n",
    "rel_train = int(0.7 * len(relevant))\n",
    "rel_dev = int(.15 * len(relevant))\n",
    "rel_fin = len(relevant) - rel_train - rel_dev\n",
    "rel_Total = rel_train + rel_dev + rel_fin\n",
    "\n",
    "irrel_train = int(0.7 * len(nonrelevant))\n",
    "irrel_dev = int(.15 * len(nonrelevant))\n",
    "irrel_fin = len(nonrelevant) - irrel_train - irrel_dev\n",
    "irrel_Total = irrel_train + irrel_dev + irrel_fin\n",
    "\n",
    "print \"Training set: %d\" %rel_train\n",
    "print \"Evaluation set: %d\" %rel_dev\n",
    "print \"Testing set: %d\" %rel_fin\n",
    "print \"Total: %d\" %rel_Total\n",
    "print \"----------------------\"\n",
    "print \"Training set: %d\" %irrel_train\n",
    "print \"Evaluation set: %d\" %irrel_dev\n",
    "print \"Testing set: %d\" %irrel_fin\n",
    "print \"Total: %d\" %irrel_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 5009\n",
      "Evaluation set: 1072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724227031</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>Two places I'd invest all my money if I could:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724227032</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>Awesome! Google driverless cars will help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724227033</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>If Google maps can't keep up with road constru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>724227034</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>Autonomous cars seem way overhyped given the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724227035</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Just saw Google self-driving car on I-34. It w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>724227036</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Will driverless cars eventually replace taxi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>724227039</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>Autonomous vehicles could reduce traffic fatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>724227040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>Driverless cars are not worth the risk.  Don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>724227041</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>Driverless cars are now legal in Florida, Cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>724227610</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Audi is the first carmaker to get a license fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id sentiment  sentiment:confidence  \\\n",
       "0   724227031         5                0.7579   \n",
       "1   724227032         5                0.8775   \n",
       "2   724227033         2                0.6805   \n",
       "3   724227034         2                0.8820   \n",
       "4   724227035         3                1.0000   \n",
       "5   724227036         3                1.0000   \n",
       "8   724227039         5                0.7187   \n",
       "9   724227040         1                0.6412   \n",
       "10  724227041         3                0.9184   \n",
       "11  724227610         3                1.0000   \n",
       "\n",
       "                                                 text  \n",
       "0   Two places I'd invest all my money if I could:...  \n",
       "1   Awesome! Google driverless cars will help the ...  \n",
       "2   If Google maps can't keep up with road constru...  \n",
       "3   Autonomous cars seem way overhyped given the t...  \n",
       "4   Just saw Google self-driving car on I-34. It w...  \n",
       "5   Will driverless cars eventually replace taxi d...  \n",
       "8   Autonomous vehicles could reduce traffic fatal...  \n",
       "9   Driverless cars are not worth the risk.  Don't...  \n",
       "10  Driverless cars are now legal in Florida, Cali...  \n",
       "11  Audi is the first carmaker to get a license fr...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sets for relevant data\n",
    "rel_train = relevant[0:4860]\n",
    "rel_dev = relevant[4860:5901]\n",
    "rel_fin = relevant[5901:6943]\n",
    "\n",
    "# Make sets for non-relevant data\n",
    "irrel_train = nonrelevant[0:149]\n",
    "irrel_dev = nonrelevant[149:180]\n",
    "irrel_fin = nonrelevant[180:231]\n",
    "\n",
    "# Combine sets by set types\n",
    "train_set = pd.concat([rel_train, irrel_train], axis=0)\n",
    "dev_set = pd.concat([rel_dev, irrel_dev], axis=0)\n",
    "final_set = pd.concat([rel_fin, irrel_fin], axis=0)\n",
    "\n",
    "# Determine lengths and compare to set size estimates\n",
    "print \"Training set: %d\" %len(train_set)\n",
    "print \"Evaluation set: %d\" %len(dev_set)\n",
    "\n",
    "train_set[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5009"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = train_set[['text', 'sentiment']]\n",
    "tuples = [tuple(x) for x in subset.values]\n",
    "\n",
    "train_set[['text']][0:10]\n",
    "subset[['text']]\n",
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#all_words =subset[['text']] \n",
    "\n",
    "all_words=toktok.tokenize(subset[['text']] )\n",
    "\n",
    "#all_words\n",
    "#all_words = set(word.lower() for passage in tuples for word in toktok.tokenize(passage[0]))\n",
    "t = [({word: (word in (x[0])) for word in all_words}, x[1]) for x in tuples]\n",
    "len(t)\n",
    "\n",
    "training_set = t[:3500]\n",
    "testing_set =  t[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    cool = True                5 : 3      =     48.8 : 1.0\n",
      "                    seem = True                1 : 3      =     41.0 : 1.0\n",
      "                    Damn = True                1 : 3      =     41.0 : 1.0\n",
      "                    Fuck = True                1 : 3      =     41.0 : 1.0\n",
      "                  reduce = True                5 : 3      =     22.8 : 1.0\n",
      "                    used = True                1 : 3      =     18.6 : 1.0\n",
      "                  window = True                1 : 3      =     17.6 : 1.0\n",
      "                  places = True                5 : 3      =     16.3 : 1.0\n",
      "                   given = True                1 : 3      =     13.7 : 1.0\n",
      "                    mean = True                1 : 3      =     12.5 : 1.0\n",
      "('Naive Bayes Classifier accuracy percent:', 40.75546719681908)\n",
      "('MNB_classifier accuracy percent:', 50.76209410205435)\n",
      "('BernoulliNB_classifier accuracy percent:', 42.080848243870115)\n",
      "('LogisticRegression_classifier accuracy percent:', 52.948972829688536)\n",
      "('SGDClassifier_classifier accuracy percent:', 23.724320742213386)\n",
      "('LinearSVC_classifier accuracy percent:', 53.8104705102717)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "classifier.show_most_informative_features()\n",
    "\n",
    "print(\"Naive Bayes Classifier accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100,\"and SGD Classifier\" (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
